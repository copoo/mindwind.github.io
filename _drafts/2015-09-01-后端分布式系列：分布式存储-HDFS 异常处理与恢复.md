---
layout    : post
title     : 后端分布式系列：分布式存储-HDFS 异常处理与恢复
date      : 2015-09-01
author    : mindwind
categories: blog
tags      : 分布式存储 HDFS 异常 恢复
image     : /assets/article_images/2015-09-01.jpg
---


在前面的文章 [《HDFS DataNode 设计实现解析》]({% post_url 2015-08-20-后端分布式系列：分布式存储－HDFS Datanode 设计实现解析 %})
中我们对文件操作进行了描述，但并未展开讲述其中涉及的异常错误处理与恢复机制。
本文将深入探讨 HDFS 文件操作涉及的错误处理与恢复过程。


## 读异常与恢复
读文件可能发生的异常有两种：

  1. 读取过程中 DataNode 挂了
  2. 读取到的文件数据损坏

HDFS 的文件块多副本分散存储机制保障了数据存储的可靠性，
对于第一种情况 DataNode 挂了只需要失败转移到其他副本所在的 DataNode 继续读取，
而对于第二种情况读取到的文件数据块若校验失败可认定为损坏，依然可以转移到读取其他完好的副本，
并向 NameNode 汇报文件 block 损坏，损坏的文件 block 的后续处理为 NameNode 通知 DataNode 删除损坏文件，
并根据完好的副本来复制一份新的文件块副本。

因为读文件不涉及数据的改变，所以处理起来相对简单，恢复机制的透明性和易用性都非常好。


## 写异常与恢复
之前的文章中对写文件的过程做了描述，这个过程中可能发生多种不同的错误异常对应着不同的处理方式。
先看看有哪些可能的异常？

### 异常模式
可能的异常模式如下所列：

  - Client 在写入过程中，自己挂了
  - Client 在写入过程中，有 DataNode 挂了
  - Client 在写入过程中，NameNode 挂了

对于以上所列的异常模式，都有分别对应的恢复模式。

### 恢复模式
当 Client 在写入过程中，自己挂了。由于 Client 在写文件之前需要向 NameNode 申请该文件的租约（lease），
只有持有租约才允许写，而且租约需要定期续约。所以当 Client 挂了后租约会超时，HDFS 在超时后会释放该文件的租约并关闭该文件，
避免文件一直被这个挂掉的 Client 独占导致其他人不能写入。这个过程称为 lease recovery。

在发起 lease recovery 时，若多个 replica 在多个 DataNodes 上处于不一致的状态，首先需要将其恢复到一致长度的状态。
这个过程称为 block recovery。 这个过程只能在 lease recovery 过程中发起。

当 Client 在写入过程中，有 DataNode 挂了。写入过程不会立刻终止（如果立刻终止，易用性和可用性都太不友好），
取而代之 HDFS 尝试从流水线中摘除挂了的 DataNode 并恢复写入，这个过程称为 pipeline recovery。

当 Client 在写入过程中，NameNode 挂了。这里的前提是已经开始写入了，所以 NameNode 已经完成了对 DataNode 的分配，
若一开始 NameNode 就挂了，整个 HDFS 是不可用的所以也无法开始写入。写入流水线过程中，当一个 block 写完后需向 NameNode 报告其状态，
这时 NameNode 挂了，状态报告失败，但不影响 DataNode 的流线工作，数据先被保存下来，
但最后一步 Client 写完向 NameNode 请求关闭文件时会出错，由于 NameNode 的单点特性，所以无法自动恢复，需人工介入恢复。

上面先简单介绍了对应异常的恢复模式，详细过程后文再描述。在介绍详细恢复过程前，需要了解文件数据状态的概念。
因为写文件过程中异常和恢复会对数据状态产生影响，我们知道 HDFS 文件至少由 1 个或多个 block 构成，因此每个 block 都有其相应的状态，
由于文件的元数据在 NameNode 中管理而文件数据本身在 DataNode 中管理，为了区分文件 block 分别在 NameNode 和 DataNode 上下文语境中的区别，
下面我们会用 replica（副本）特指在 DataNode 中的 block，而 block 则限定为在 NameNode 中的文件块元数据信息。
在这个语义限定下 NameNode 中的 block 实际对应 DataNodes 上的多个 replicas，它们分别有不同的数据状态。
我们先看看 replica 和 block 分别在 DataNode 和 NameNode 中都存在哪些状态？

### Replica 状态
Replica 在 DataNode 中存在的状态列表如下：

  - __FINALIZED__：
  表明 replica 的写入已经完成，长度已确定，除非该 replica 被重新打开并追加写入。
  - __RBW__：
  该状态是 Replica Being Written 的缩写，表明该 replica 正在被写入，正在被写入的 replica 总是打开文件的最后一个块。
  - __RWR__：
  该状态是 Replica Waiting to be Recovered 的缩写，假如写入过程中 DataNode 挂了重启后，
  其上处于 RBW 状态的 replica 将被变更为 RWR 状态，这个状态说明其数据需要恢复，因为在 DataNode 挂掉期间其上的数据可能过时了。
  -__RUR__：
  该状态是 Replica Under Recovery 的缩写，表明该 replica 正处于恢复过程中。
  -__TEMPORARY__：
  一个临时状态的 replica 是因为复制或者集群平衡的需要而创建的，若复制失败或其所在的 DataNode 发生重启，所有临时状态的 replica 会被删除。
  临时态的 replica 对外部 Client 来说是不可见的。

DataNode 会持久化存储 replica 的状态，每个数据目录都包含了三个子目录：

  - current：目录包含了 `FINALIZED` 状态 replicas。
  - tmp：目录包含了 `TEMPORARY` 状态的 replicas。
  - rbw：目录则包含了 `RBW`、`RWR` 和 `RUR` 三种状态的 relicas，从该目录下加载的 replicas 默认都处于 `RWR` 状态。

下图展示了 replica 的状态变化过程。
![](/assets/article_images/2015-09-01-1.png)  
接下我们再看看 NameNode 上 block 的状态有哪些以及时如何变化的。

### Block 状态
Block 在 NameNode 中存在的状态列表如下：

  -__UNDER_CONSTRUCTION__：
  当新创建一个 block 或一个旧的 block 被重新打开追加时，它是一个打开文件的最后一个 block。
  -__UNDER_RECOVERY__：
  当文件租约超时，一个处于 `UNDER_CONSTRUCTION` 状态下 block 在 block recovery 过程开始后会修改到该状态。
  -__COMMITTED__：
  表明 block 数据已经不会发生变化，但向 NameNode 报告处于 `FINALIZED` 状态的 replica 数量少于最小副本数。
  -__COMPLETE__：
  当 NameNode 收到处于 `FINALIZED` 状态的 replica 数量达到最小副本数后，则切换到改状态。只有当文件的所有 block 处于该状态才可被关闭。

NameNode 不会持久化存储这些状态，一旦 NameNode 发生重启，它将所有打开文件的最后一个 block 设置为 `UNDER_CONSTRUCTION` 状态，
其他则全部设置为 `COMPLETE` 状态。

下图展示了 block 的状态变化过程。
![](/assets/article_images/2015-09-01-1.png)  
理解了 block 和 replica 的状态及其变化过程，我们就可以进一步详细分析上述简要提及的几种自动恢复模式。

### Lease Recovery



### Block Recovery


### Pipeline Recovery


## 总结



## 参考
[1] Hadoop Documentation. [HDFS Architecture](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html).
[2] Robert Chansler, Hairong Kuang, Sanjay Radia, Konstantin Shvachko, and Suresh Srinivas. [The Hadoop Distributed File System](http://www.aosabook.org/en/hdfs.html)
[3] Tom White. [Hadoop: The Definitive Guide](http://book.douban.com/subject/10464777/). O'Reilly Media(2012-05), pp 94-96
[4] Yongjun Zhang. [Understanding HDFS Recovery Processes](http://blog.cloudera.com/blog/2015/02/understanding-hdfs-recovery-processes-part-1/)
[5] Hairong Kuang, Konstantin Shvachko, Nicholas Sze, Sanjay Radia,  Robert Chansler , Yahoo! HDFS team  [Design Specification: Append/Hflush/Read Design ](https://issues.apache.org/jira/secure/attachment/12445209/appendDesign3.pdf)
[6] HDFSteam. [Design Specification: HDFS Append and Truncates](https://issues.apache.org/jira/secure/attachment/12370562/Appends.doc)
