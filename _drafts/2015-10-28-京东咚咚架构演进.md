---
layout    : post
title     : 京东咚咚架构演进
date      : 2015-10-28
author    : mindwind
categories: blog
tags      : 京东咚咚 架构
image     : /assets/article_images/2015-10-28.jpg
elapse    :
---


咚咚是什么？咚咚之于京东相当于旺旺之于淘宝，它们都是服务于买家和卖家的沟通。
自从京东开始为第三方卖家提供入驻平台服务后，咚咚也就随之诞生了。
我们首先看看它诞生之初是什么样的。


## 1.0 诞生（2010 - 2011)
为了业务的快速上线，1.0 版本的技术架构实现是非常直接且简单粗暴的。
如何简单粗暴法？请看架构图，如下。  
![](/assets/article_images/2015-10-28-1.png)

1.0 的功能十分简单，实现了一个 IM 的基本功能，接入、互通消息和状态。
另外还有个客服功能，就是顾客接入咨询时的客服分配，按轮询方式把顾客分配给在线的客服接待。
用开源 Mina 框架实现了 TCP 的长连接接入，用 Tomcat Comet 机制实现了 HTTP 的长轮询服务。
而消息投递的实现是一端发送的消息临时存放在 Redis 中，另一端拉取的生产消费模型。

这个模型的做法导致需要以一种较高频率的方式来轮询 Redis 遍历属于自己连接关联会话的消息。
这个模型很简单，简单包括多个层面的意思：理解起来简单；开发起来简单；部署起来也简单。
只需要一个 Tomcat 应用依赖一个共享的 Redis，简单的实现核心业务功能，并支持业务快速上线。

但这个简单的模型也有些严重的缺陷，主要是效率和扩展问题。
轮询的频率间隔大小基本决定了消息的延时，轮询越快延时越低，但轮询越快消耗也越高。
这个模型实际上是一个高功耗低效能的模型，因为不活跃的连接在那做高频率的无意义轮询。
高频有多高呢，基本在 100 ms 以内，你不能让轮询太慢，比如超过 2 秒轮一次，人就会在聊天过程中感受到明显会话延迟。
随着在线人数增加，轮询的耗时也线性增长，因此这个模型导致了扩展能力和承载能力都不好，一定会随着在线人数的增长碰到性能瓶颈。

1.0 的时代背景正是京东技术平台从 .NET 向 Java 转型的年代，我也正是在这期间加入京东并参与了京东主站技术转型架构升级的过程。
之后开始接手了京东咚咚，并持续完善这个产品，进行了三次技术架构演进。


## 2.0 成长（2012）
我们刚接手时 1.0 已在线上运行并支持京东 POP（开放平台）业务，之后京东打算组建自营在线客服团队并落地在了成都。
不管是自营还是 POP 客服咨询业务当时都起步不久，1.0 架构中的性能和效率缺陷问题还没有达到引爆的业务量级。
而自营客服当时还处于起步阶段，客服人数不足，服务能力不够，顾客咨询量远远超过客服的服务能力。
超出服务能力的顾客咨询，当时我们的系统统一返回提示客服繁忙，请稍后咨询。
这种状况导致高峰期大量顾客无论怎么刷新请求，都很可能无法接入客服，体验很差。
所以 2.0 重点放在了业务功能体验的提升上，如下图所示。  
![](/assets/article_images/2015-10-28-2.png)

针对无法及时提供服务的顾客，可以排队或者留言。
针对纯文字沟通，提供了文件和图片等更丰富的表达方式。
另外支持了客服转接和快捷回复等方式来提升客服的接待效率。
总之，整个 2.0 就是围绕提升客服效率和用户体验。
而我们担心的效率问题在 2.0 高速发展业务的时期还没有出现，但业务量正在逐渐积累，我们知道它快要爆了。
到 2012 年末，度过双十一后开始了 3.0 的一次重大架构升级。


## 3.0 爆发（2013 - 2014）
经历了 2.0 时代一整年的业务高速发展，实际上代码规模膨胀的很快。
与代码一块膨胀的还有团队，从最初的 4 个人到近 30 人。
团队大了后，一个系统多人开发，开发人员层次不一，规范难统一，系统模块耦合重，改动沟通和依赖多，上线风险难以控制。
一个单独 tomcat 应用多实例部署模型终于走到头了，这个版本架构升级的主题就是服务化。

服务化的第一个问题如何把一个大的应用系统切分成子服务系统。
当时的背景是京东的部署还在半自动化时代，自动部署系统刚起步，子服务系统若按业务划分太细太多，部署工作量很大且难管理。
所以当时我们不是按业务功能分区服务的，而是按业务重要性级别划分了 0、1、2 三个级别不同的子业务服务系统。
另外就是独立了一组接入服务，针对不同渠道和通信方式的接入端，见下图。  
![](/assets/article_images/2015-10-28-3.png)

这次大的架构升级，主要考虑了三个方面：稳定性、效率和容量。
做了下面这些事情：
  1. 业务分级、核心、非核心业务隔离
  2. 多机房部署，流量分流、容灾冗余、峰值应对冗余
  3. 读库多源，失败自动转移
  4. 写库主备，短暂有损服务容忍下的快速切换
  5. 外部接口，失败转移或快速断路
  6. Redis 主备，失败转移
  7. MongoDB 取代 MySQL 存储消息记录
  8. 改进消息投递模型


前 6 条基本属于考虑系统稳定性、可用性方面的改进升级。
这一块属于陆续迭代完成的，承载很多失败转移的配置和控制功能在上面图中是由管控中心提供的。
第 7 条主要是随着业务量的上升，单日消息量越来越大后，使用了 MongoDB 来单独存储量最大聊天记录。
第 8 条是针对 1.0 版本消息轮询效率低的改进，改进后的投递方式如下图所示：  
![](/assets/article_images/2015-10-28-4.png)

不再是轮询了，而是让终端每次建立连接后注册接入点位置，消息投递前定位连接所在接入点位置再推送过去。
这样投递效率就是恒定的了，而且很容易扩展，在线人数越多则连接数越多，则只需要扩展接入点即可。
其实，这个模型依然还有些小问题，主要出在离线消息的处理上，可以先思考下，我们下面再讲。

3.0 经过了两年的迭代式升级，单纯从业务量上来说还可以继续支撑很长时间的增长。
但实际上到 2014 年底我们面对的不再是业务量的问题，而是业务模式的变化。
这直接导致了一个全新时代的到来。
