---
layout    : post
title     : 后端分布式系列：分布式存储－Redis 的性能幻想与残酷现实
date      : 2015-12-25
author    : mindwind
categories: blog
tags      : Redis 性能
image     : /assets/article_images/2015-12-25.jpg
elapse    :
---





## 参考
[1] antirez. [Redis Documentation](http://redis.io/documentation)  
When an ethernet network is used to access Redis, aggregating commands using pipelining is especially efficient when the size of the data is kept under the ethernet packet size (about 1500 bytes). Actually, processing 10 bytes, 100 bytes, or 1000 bytes queries almost result in the same throughput. See the graph below.

As a rule of thumb, an instance with 30000 connections can only process half the throughput achievable with 100 connections.


[2] antirez. [Clarifications about Redis and Memcached](http://antirez.com/news/94)
[3] antirez. [Lazy Redis is better Redis](http://antirez.com/news/93)


[4] antirez. [On Redis, Memcached, Speed, Benchmarks and The Toilet](http://oldblog.antirez.com/post/redis-memcached-benchmark.html)
Even if Redis provides much more features than memcached, including persistence, complex data types, replication, and so forth, it's easy to say that it is an almost strict superset of memcached.

This is a limited test that can't be interpreted as Redis is faster. It is surely faster under the tested conditions, but different real world work loads can lead to different results. For sure after this tests I've the impressions that the two systems are well designed, and that in Redis we are not overlooking any obvious optimization.

[5] antirez, [An update on the Memcached/Redis benchmark](http://oldblog.antirez.com/post/update-on-memcached-redis-benchmark.html)
is a multi threaded implementation worth it?
This is a matter of design, tastes, and facts all mixed together. With a single instance using multiple threads you have a few advantages:
  - No sharding if you want to use a single server.
  - If your application performs a lot of GET operations with multiple keys per time, a single instance does not force you to take multiple connections and to send more requests in parallel, that is less straightforward.
There are also disadvantages:
  - Slower development speed to achieve the same features. Multi thread programming is hard.
  - It's harder to fix bugs. The only place of the Redis code base where we experienced hard to fix bugs was the Virtual Memory, that is threaded (because it is the only way to do it well).
  - Not as scalable.
  - If you are dealing with complex atomic operations like Redis does, it can become a nightmare.
  - Once Redis 2.2 will be stable we'll focus on Redis Cluster, that will mitigate the pain of running a cluster of instances. This is a non issue with memcached mostly as it's used for caching and   client-side sharding is perfectly fine for this application.

[6] dormando. [Redis VS Memcached (slightly better bench)](http://dormando.livejournal.com/525147.html)
memcached is multi-threaded and has a very, very high performance ceiling. redis is single-threaded and is very performant on its own.
Computers are absolutely trending toward more cores and not toward higher clocks. Threading is how we will scale single instances.
Understand what your app needs feature-wise, scale-wise, and performance-wise, then use the right tool for the damn job. Don't just read benchmarks and flip around ignorantly, please :)

[7] Mike Perham. [Storing Data with Redis](http://www.mikeperham.com/2015/09/24/storing-data-with-redis/)
At the same time I see lots of people using Redis in the most naive way possible: put everything into one database.

Redis is single-threaded and can perform X ops/sec so consider that your performance “budget”. Datasets in the same Redis instance will share that budget. What happens when your traffic spikes and the cache data uses the entire budget? Now your job queue slows to a crawl.

I recommend memcached because it is designed for caching: it performs no disk I/O at all and is multithreaded so it can scale across all cores, handling 100,000s of requests per second. Redis is limited to a single core so it will hit a scalability limit before memcached. Using Redis for caching is totally reasonable if you want to stick with one tool and are comfortable with the necessary configuration and lower scalability limit per process. Redis does have a nice advantage that it can persist the cache, making it much faster to warm up upon restart.


[8] 温柔一刀. [Redis 常见的性能问题和解决方法](http://zhupan.iteye.com/blog/1576108).

![](/assets/images/qrcode_tail.jpg)
